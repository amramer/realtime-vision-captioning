{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7QyQO6Vwett"
   },
   "source": [
    "# Automated Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843,
     "referenced_widgets": [
      "148d15e5ae6b45208444ab5e372a9916",
      "7ea9f812ee9b4cf586e1698c354820d7",
      "d2b636345ad64e0b8c7edfd6050465c2",
      "0d9c0c1b55154aacb3cf0427da466c72",
      "f2494bec374a400aad42342ff8d86cfb",
      "67c81feb9e994ee3b418cfe7bcaf8b3b",
      "06ec70ce6a894894b2f173d6be413051",
      "7e44a7bff0994e2fae811ff6747bc95d",
      "6af91750d04941318736b979b801aea2",
      "3ff292402e964daa9f68be18de01a2fb",
      "0b92e919d670499a8785f37af47ba7b8",
      "643b30003ff64aa7950a4e5224968df1",
      "e4ba2523297548a4a231f5aa29965e9d",
      "77d509bace184480b6dfe3cbbabd27e3",
      "20f9ad8935c84c8db5e7d9cb1ecfc977",
      "6faf34ad663347b9a36d822b76c7ca88",
      "d287451a43ea455ea49818c340b6c8d1",
      "fe20cec8d3d54919a580304f32cc9c78",
      "d294a7b775f34f17ae30a14c299fff44",
      "399c8c12ecf049d187ab09e24a74a441",
      "a73fb4f32af240d5975284bcab5217db",
      "14078b8c439246f6b2a7681646f5dbdd",
      "d5ac72608cb04354ae58c142aaf6771f",
      "2acfe22d4d3a4f0db0cee137a097ab1c",
      "3d1610111d2f414092f27de38022222f",
      "4c7ea43f7a304471bbd8b34cd0b42d42",
      "1ad964c8ab2b4e5cbd8f1f95514fb7b1",
      "6b43d85a60c646a1b9caeebd74be8a97",
      "7ffd535450d246b1867d95d73ef702e0",
      "6aa78dafd75242f381d77eb0829374fb",
      "9a59f8cbbb534c7e8fd1553377541a6f",
      "7593dee64849492cbe3f172003374653",
      "17c72d999ea64feda1b6b35ab94f6a73",
      "ceb185dc84c44a26b52944585341738f",
      "e2c05bcfc0554539be7de9d8e8998067",
      "b4fdf4d3e5a24510b9b5d5a6e4f21eea",
      "9c48742b43e5477295b60c1762485f84",
      "c8d7f02c13264b3c82b443db0ec02eab",
      "be8ec9df62c9478fa6e5807688126e17",
      "ba4c7ffb1898436d934ff9e2cf8eee55",
      "7b771668fb3549bf9ceb79a733bf3fb4",
      "b16c7f7c789f43cab03819be50894183",
      "cd7e6c8280e4449a87cdcc6c379ea084",
      "211077faabed4328834389b9d8dbb510",
      "1623918f68d1429c8857ad04d9d6c1eb",
      "0cdbb813f0e44cbaa26a272b7d77371f",
      "030c809090c64cb9a0d9d33f9a688bee",
      "64e9c703e5eb4126b1331022aaf2fae2",
      "abcae4f91ef844e4916ee724899d7cd1",
      "d90cfc9633334482adbd0b1807fa997f",
      "9c789c7cb9654d11a994674283ee17e5",
      "b13951caa7c14e12948b963c477d0bb9",
      "cb08a583de2a4e9fa7002cad8a5eb14c",
      "f56dbc934eb741a89f83f84ab281ae4a",
      "417d617856824e27bc8ca7c2a1c895d5",
      "0fcf52d93f5b4179b237980d9ca3cb3b",
      "a92d9ecb468b403badf91bac2e59b563",
      "7fac8255881843d1965c1fd29926a3af",
      "4b7f4e6442ee46d4a11d6ec7ab30468d",
      "426f81aa264b4643b6f8ff9dc954fcee",
      "e50a52dcc4044dec96c24b7243159641",
      "9c72dd05095a4b2bbe9567665164881b",
      "0c275e7bd0774a2aae35ef99ec4be4c0",
      "e8392d6a021440f09c486c72426b69d0",
      "4662150de06f408199f500f9d761d931",
      "c0ae2832999c4b40bbc3f28ac323a24e",
      "d5d5baaaf4c54ffb8c08579ec5f57861",
      "e5f721b0f5c14fe58722c747df7e96da",
      "9c98903380934dca8bc72c7671f3f6a7",
      "68d08ca8326f484f982357d06df95f96",
      "222f7598f32c41139f6dae56db1fa89f",
      "8b9ed913395443ec94bf168644fe5675",
      "36b07e9991a547418850dff90576f18b",
      "ca871edeaead4e4a800aa52e2ab79030",
      "cf4f59fb201e4874b3c6c047f2f5ac7d",
      "f96efd662f2c4b10bffd9c842c3d9821",
      "16e9280eb8274913b80d7a5f78f92f68",
      "b239f9f524b643d0b70a93d62e706b51",
      "17de34a6b58d4ab892d7861b62ce251d",
      "4b6a8d963baa4ffcac9d95ccf88b0601",
      "dbcdfaf099f64dd2be7cdcc9d67f41ca",
      "7dfde0bf78bf4698b691e49a83de80fd",
      "6768ff76d3244884b69b855120e2af61",
      "99af7a9c9368403bbf7017c341c4ee63",
      "b0f1a869ff4e419f972c3052b679620e",
      "8c73b39c951d481eaeba57bd2b7779c9",
      "e1cd5f798fa548a0a28ae669da3745bf",
      "621ed6cd165049e3a770c2384c352cb2"
     ]
    },
    "id": "GXvaaiciwTFZ",
    "outputId": "0cce2a02-1893-4c5e-8f41-90d720bd9411"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "# Image URL\n",
    "image_url = \"https://picsum.photos/id/237/800/600.jpg\"\n",
    "\n",
    "# Load image from URL\n",
    "image = Image.open(requests.get(image_url, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "# Initialize BLIP processor and model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Prepare the image\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "# Generate caption\n",
    "outputs = model.generate(**inputs)\n",
    "caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Show image and caption (inline)\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Generated Caption: {caption}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Generated Caption:\", caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0H6I139wsiJ"
   },
   "source": [
    "## Image Captioning with Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1ngGxoMwwoZ"
   },
   "outputs": [],
   "source": [
    "# install\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "f8Xo2KAjw2e3",
    "outputId": "61d99ff6-6ec0-4146-a587-46c6f9f2012b"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Config\n",
    "# -----------------------------\n",
    "MODEL_NAME = \"Salesforce/blip-image-captioning-base\"\n",
    "\n",
    "EXAMPLE_IMAGES = [\n",
    "    \"https://images.unsplash.com/photo-1501785888041-af3ef285b470\",\n",
    "    \"https://images.unsplash.com/photo-1500530855697-b586d89ba3ee\",\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Load processor + model (once)\n",
    "# -----------------------------\n",
    "processor = BlipProcessor.from_pretrained(MODEL_NAME)\n",
    "model = BlipForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Captioning logic\n",
    "# -----------------------------\n",
    "def generate_caption(image: Image.Image, max_new_tokens: int = 30, num_beams: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Generate an image caption using BLIP.\n",
    "    image: PIL.Image\n",
    "    \"\"\"\n",
    "    image = image.convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_beams=num_beams,\n",
    "    )\n",
    "    caption = processor.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "def caption_image(image: Image.Image, max_new_tokens: int, num_beams: int) -> str:\n",
    "    \"\"\"\n",
    "    Gradio wrapper: Takes a PIL Image input and returns a caption.\n",
    "    \"\"\"\n",
    "    if image is None:\n",
    "        return \"Please upload an image or pick an example.\"\n",
    "\n",
    "    try:\n",
    "        return generate_caption(image, max_new_tokens=max_new_tokens, num_beams=num_beams)\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Gradio UI\n",
    "# -----------------------------\n",
    "with gr.Blocks(title=\"Automated Image Captioning (BLIP)\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "# Automated Image Captioning (BLIP)\n",
    "Upload an image (or select an example) to generate a caption using **Salesforce BLIP**.\n",
    "        \"\"\".strip()\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        image_in = gr.Image(type=\"pil\", label=\"Input Image\")\n",
    "        caption_out = gr.Textbox(label=\"Generated Caption\", lines=3)\n",
    "\n",
    "    with gr.Accordion(\"Advanced settings\", open=False):\n",
    "        max_new_tokens = gr.Slider(5, 80, value=30, step=1, label=\"Max new tokens\")\n",
    "        num_beams = gr.Slider(1, 10, value=5, step=1, label=\"Beam search (num_beams)\")\n",
    "\n",
    "    btn = gr.Button(\"Generate Caption\")\n",
    "\n",
    "    # Examples appear beside/below the upload widget (depending on screen width)\n",
    "    gr.Examples(\n",
    "        examples=[[EXAMPLE_IMAGES[0]], [EXAMPLE_IMAGES[1]]],\n",
    "        inputs=[image_in],\n",
    "        label=\"Try examples\",\n",
    "    )\n",
    "\n",
    "    # Actions\n",
    "    btn.click(\n",
    "        fn=caption_image,\n",
    "        inputs=[image_in, max_new_tokens, num_beams],\n",
    "        outputs=[caption_out],\n",
    "    )\n",
    "\n",
    "    # Optional: auto-update when image changes (similar to live=True but controlled)\n",
    "    image_in.change(\n",
    "        fn=caption_image,\n",
    "        inputs=[image_in, max_new_tokens, num_beams],\n",
    "        outputs=[caption_out],\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vm8mKxxuw7_K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
